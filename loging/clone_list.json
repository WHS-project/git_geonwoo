[
  {
    "Pull request index": 1,
    "PR title": "[BugFix] Fix osx tests",
    "PR URL": "https://github.com/pytorch/tensordict/pull/591",
    "created_at": "2023-12-05T11:18:39Z",
    "updated_at": "2023-12-05T12:06:19Z",
    "closed_at": "2023-12-05T12:06:05Z",
    "body": "## Description\n\nDescribe your changes in detail.\n\n## Motivation and Context\n\nWhy is this change required? What problem does it solve?\nIf it fixes an open issue, please link to the issue here.\nYou can use the syntax `close #15213` if this solves the issue #15213\n\n- [ ] I have raised an issue to propose this change ([required](https://github.com/pytorch/tensordict/issues) for new features and bug fixes)\n\n## Types of changes\n\nWhat types of changes does your code introduce? Remove all that do not apply:\n\n- [ ] Bug fix (non-breaking change which fixes an issue)\n- [ ] New feature (non-breaking change which adds core functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\n- [ ] Documentation (update in the documentation)\n- [ ] Example (update in the folder of examples)\n\n## Checklist\n\nGo over all the following points, and put an `x` in all the boxes that apply.\nIf you are unsure about any of these, don't hesitate to ask. We are here to help!\n\n- [ ] I have read the [CONTRIBUTION](https://github.com/pytorch/tensordict/blob/main/CONTRIBUTING.md) guide (**required**)\n- [ ] My change requires a change to the documentation.\n- [ ] I have updated the tests accordingly (*required for a bug fix or a new feature*).\n- [ ] I have updated the documentation accordingly.\n",
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/591.diff",
    "merged_at": "2023-12-05T12:06:05Z"
  },
  {
    "Pull request index": 2,
    "PR title": "[BugFix] Fix non-blocking arg in copy_",
    "PR URL": "https://github.com/pytorch/tensordict/pull/590",
    "created_at": "2023-12-04T13:54:06Z",
    "updated_at": "2023-12-04T14:02:25Z",
    "closed_at": "2023-12-04T13:54:35Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/590.diff",
    "merged_at": "2023-12-04T13:54:35Z"
  },
  {
    "Pull request index": 3,
    "PR title": "Update create_pgsnapshot in purefa_pgsnap.py renaming throttle parame\u2026",
    "PR URL": "https://github.com/Pure-Storage-Ansible/FlashArray-Collection/pull/516",
    "created_at": "2023-12-01T16:47:20Z",
    "updated_at": "2023-12-01T18:41:09Z",
    "closed_at": "2023-12-01T17:05:24Z",
    "body": "\u2026ter of protection_group_snapshots_post to allow_throttle\r\n\r\n\"create_pgsnapshot\" in plugins/modules/purefa_pgsnap.py calls \"protection_group_snapshots_api.py\" from the py-pure-client with the wrongly named parameter \"throttle\" instead of \"allow_throttle\" to fail if array health is not optimal.\r\n\r\nThis causes the error:\r\nTraceback (most recent call last):\r\n  File \"[...]/AnsiballZ_purefa_pgsnap.py\", line 107, in <module>\r\n    _ansiballz_main()\r\n  File \"[...]/AnsiballZ_purefa_pgsnap.py\", line 99, in _ansiballz_main\r\n    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)\r\n  File \"[...]/AnsiballZ_purefa_pgsnap.py\", line 47, in invoke_module\r\n    runpy.run_module(mod_name='ansible_collections.purestorage.flasharray.plugins.modules.purefa_pgsnap', init_globals=dict(_module_fqn='ansible_collections.purestorage.flasharray.plugins.modules.purefa_pgsnap', _modlib_path=modlib_path),\r\n  File \"/usr/lib64/python3.9/runpy.py\",line 225, in run_module\r\n    return _run_module_code(code, init_globals, run_name, mod_spec)\r\n  File \"/usr/lib64/python3.9/runpy.py\", line 97, in _run_module_code\r\n_run_code(code, mod_globals, init_globals,\r\n  File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"[...]/purefa_pgsnap.py\", line 615, in <module>\r\n  File \"[...]/purefa_pgsnap.py\", line 593, in main\r\n  File \"[...]/purefa_pgsnap.py\", line 336, in create_pgsnapshot\r\nTypeError: post_protection_group_snapshots() got an unexpected keyword argument 'throttle'\r\n\r\n##### SUMMARY\r\n<!--- Describe the change below, including rationale and design decisions -->\r\n\r\n<!--- HINT: Include \"Fixes #nnn\" if you are fixing an existing issue -->\r\n\r\n##### ISSUE TYPE\r\n<!--- Pick one below and delete the rest -->\r\n- Bugfix Pull Request\r\n\r\n##### COMPONENT NAME\r\npurefa_pgsnap.py",
    "repository_url": "https://api.github.com/repos/Pure-Storage-Ansible/FlashArray-Collection",
    "repository_clone_url": "https://github.com/Pure-Storage-Ansible/FlashArray-Collection",
    "repository_name": "FlashArray-Collection",
    "diff_url": "https://github.com/Pure-Storage-Ansible/FlashArray-Collection/pull/516.diff",
    "merged_at": "2023-12-01T17:05:24Z"
  },
  {
    "Pull request index": 4,
    "PR title": "[BugFix] Adapt MemoryMappedTensor for torch < 2.0",
    "PR URL": "https://github.com/pytorch/tensordict/pull/587",
    "created_at": "2023-11-30T21:04:58Z",
    "updated_at": "2023-11-30T21:14:16Z",
    "closed_at": "2023-11-30T21:05:45Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/587.diff",
    "merged_at": "2023-11-30T21:05:45Z"
  },
  {
    "Pull request index": 5,
    "PR title": "[BugFix] Faster empty_like for MemoryMappedTensor (dup)",
    "PR URL": "https://github.com/pytorch/tensordict/pull/586",
    "created_at": "2023-11-30T10:15:22Z",
    "updated_at": "2023-11-30T10:24:10Z",
    "closed_at": "2023-11-30T10:16:20Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/586.diff",
    "merged_at": "2023-11-30T10:16:20Z"
  },
  {
    "Pull request index": 6,
    "PR title": "[BugFix] Faster empty_like for MemoryMappedTensor",
    "PR URL": "https://github.com/pytorch/tensordict/pull/585",
    "created_at": "2023-11-30T10:10:29Z",
    "updated_at": "2023-11-30T10:21:15Z",
    "closed_at": "2023-11-30T10:12:14Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/585.diff",
    "merged_at": "2023-11-30T10:12:14Z"
  },
  {
    "Pull request index": 7,
    "PR title": "Bugfix: Fail with informational error message in case of broken unicode in CLI args",
    "PR URL": "https://github.com/codemagic-ci-cd/cli-tools/pull/376",
    "created_at": "2023-11-30T09:44:54Z",
    "updated_at": "2023-12-01T10:36:07Z",
    "closed_at": "2023-12-01T10:36:06Z",
    "body": "When invalid unicode sequences are passed to programs via CLI arguments, then down the line number of weird things can happen. Starting from logging issues up to final broken application logic. For example consider the following snippet:\r\n```bash\r\n#!/bin/sh\r\n\r\nexport APP_STORE_APP_ID=1496105355\r\n# note the invalid quotes\r\napp-store-connect apps get \u201c$APP_STORE_APP_ID\u201d\r\n```\r\n\r\nExecuting this script will pass application ID as `\u201c\\udc80\\udc9d` to Python program, which can cause all sorts of troubles as the value cannot be encoded:\r\n```python\r\n>>> \"\u201c\\udc80\\udc9d\".encode()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nUnicodeEncodeError: 'utf-8' codec can't encode characters in position 1-2: surrogates not allowed\r\n```\r\n\r\n<details>\r\n<summary>Full erroneous script output</summary>\r\n\r\n```shell\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/logging/__init__.py\", line 1163, in emit\r\n    stream.write(msg + self.terminator)\r\nUnicodeEncodeError: 'utf-8' codec can't encode characters in position 127-128: surrogates not allowed\r\nCall stack:\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/bin/app-store-connect\", line 8, in <module>\r\n    sys.exit(AppStoreConnect.invoke_cli())\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 201, in invoke_cli\r\n    cls._log_cli_invoke_started()\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 244, in _log_cli_invoke_started\r\n    file_logger.debug(Colors.MAGENTA(exec_line))\r\nMessage: \"\\x1b[35mExecute /Users/priit/.pyenv/versions/3.12.0/bin/app-store-connect apps get '\u201c\\udc80\\udc9d'\\x1b[0m\"\r\nArguments: ()\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/logging/__init__.py\", line 1163, in emit\r\n    stream.write(msg + self.terminator)\r\nUnicodeEncodeError: 'utf-8' codec can't encode characters in position 63-64: surrogates not allowed\r\nCall stack:\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/bin/app-store-connect\", line 8, in <module>\r\n    sys.exit(AppStoreConnect.invoke_cli())\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 213, in invoke_cli\r\n    CliApp._running_app._invoke_action(args)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 170, in _invoke_action\r\n    return cli_action(**action_args)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 465, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/tools/_app_store_connect/action_groups/apps_action_group.py\", line 39, in get_app\r\n    return self._get_resource(application_id, self.api_client.apps, should_print)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/tools/_app_store_connect/resource_manager_mixin.py\", line 57, in _get_resource\r\n    self.printer.log_get(resource_manager.resource_type, resource_id)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/tools/_app_store_connect/resource_printer.py\", line 101, in log_get\r\n    self.logger.info(f\"Get {resource_type} {resource_id}\")\r\nMessage: 'Get App \u201c\\udc80\\udc9d'\r\nArguments: ()\r\nGet App \u201c\\udc80\\udc9d\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/logging/__init__.py\", line 1163, in emit\r\n    stream.write(msg + self.terminator)\r\nUnicodeEncodeError: 'utf-8' codec can't encode characters in position 103-104: surrogates not allowed\r\nCall stack:\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/bin/app-store-connect\", line 8, in <module>\r\n    sys.exit(AppStoreConnect.invoke_cli())\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 213, in invoke_cli\r\n    CliApp._running_app._invoke_action(args)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 170, in _invoke_action\r\n    return cli_action(**action_args)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/cli/cli_app.py\", line 465, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/tools/_app_store_connect/action_groups/apps_action_group.py\", line 39, in get_app\r\n    return self._get_resource(application_id, self.api_client.apps, should_print)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/tools/_app_store_connect/resource_manager_mixin.py\", line 59, in _get_resource\r\n    resource = read_resource(resource_id)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/apple/app_store_connect/apps/apps.py\", line 67, in read\r\n    response = self.client.session.get(f\"{self.client.API_URL}/apps/{app_id}\").json()\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py\", line 602, in get\r\n    return self.request(\"GET\", url, **kwargs)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/apple/app_store_connect/api_session.py\", line 97, in request\r\n    return self._do_request(*args, **kwargs)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/apple/app_store_connect/api_session.py\", line 66, in _do_request\r\n    self._log_request(*request_args, **request_kwargs)\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/site-packages/codemagic/apple/app_store_connect/api_session.py\", line 42, in _log_request\r\n    self._logger.info(f\">>> {method} {url} {body}\")\r\nMessage: '>>> GET https://api.appstoreconnect.apple.com/v1/apps/\u201c\\udc80\\udc9d None'\r\nArguments: ()\r\nGET https://api.appstoreconnect.apple.com/v1/apps/%E2%80%9C%ED%B2%80%ED%B2%9D returned 404: The URL path is not valid - Invalid URL path\r\n```\r\n\r\n</details>\r\n\r\nAvoid this by validating that string arguments can be safely encoded. With the changes introduced in this PR the script fails still, but now with appropriate error message:\r\n```shell\r\nusage: app-store-connect [-h] [--log-stream {stderr,stdout}] [--no-color] [--version] [-s] [-v]\r\n                         {app-store-version-localizations,app-store-version-submissions,app-store-versions,apps,beta-app-review-submissions,beta-build-localizations,beta-groups,builds,create-bundle-id,create-certificate,create-profile,delete-bundle-id,delete-certificate,delete-profile,fetch-signing-files,get-bundle-id,get-certificate,get-latest-app-store-build-number,get-latest-build-number,get-latest-testflight-build-number,get-profile,list-builds,list-bundle-id-profiles,list-bundle-ids,list-certificates,list-devices,list-profiles,publish,register-device,review-submission-items,review-submissions}\r\n                         ...\r\napp-store-connect: error: Unknown encoding for argument application_id value: \u201c\\udc80\\udc9d\r\n```",
    "repository_url": "https://api.github.com/repos/codemagic-ci-cd/cli-tools",
    "repository_clone_url": "https://github.com/codemagic-ci-cd/cli-tools",
    "repository_name": "cli-tools",
    "diff_url": "https://github.com/codemagic-ci-cd/cli-tools/pull/376.diff",
    "merged_at": "2023-12-01T10:36:06Z"
  },
  {
    "Pull request index": 8,
    "PR title": "[BugFix] Delete parameter/buffer before setting it with regular setattr in to_module",
    "PR URL": "https://github.com/pytorch/tensordict/pull/583",
    "created_at": "2023-11-28T17:52:51Z",
    "updated_at": "2023-11-29T08:02:04Z",
    "closed_at": "2023-11-29T07:51:26Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/583.diff",
    "merged_at": "2023-11-29T07:51:26Z"
  },
  {
    "Pull request index": 9,
    "PR title": "Add lat and lon bounds if missing in input datasets",
    "PR URL": "https://github.com/E3SM-Project/e3sm_to_cmip/pull/228",
    "created_at": "2023-11-27T22:44:07Z",
    "updated_at": "2023-12-07T22:29:22Z",
    "closed_at": "2023-12-07T22:29:20Z",
    "body": "## Description\r\n\r\n<!--\r\n  Please include a summary of the change and which issue is fixed.\r\n  Please also include relevant motivation and context.\r\n  List any dependencies that are required for this change.\r\n-->\r\n\r\n- Closes #227 \r\n\r\nThis PR updates the `VarHandler._get_mfdataset()` to use xCDAT to open the input datasets and adds bounds for lat and lon if they are missing.\r\n\r\n### Minimum Reproducible Script\r\n```python\r\nfrom e3sm_to_cmip.__main__ import E3SMtoCMIP\r\n\r\nargs = [\r\n    \"--var-list\",\r\n    \"lai\",\r\n    \"--input\",\r\n    \"/lcrc/group/e3sm/ac.zhang40/tests/20231012.v3alpha04_trigrid_bgc.piControl.chrysalis/post/lnd/native/ts/monthly/50yr\",\r\n    \"--output\",\r\n    \"./\",\r\n    \"--tables-path\",\r\n    \"/lcrc/group/e3sm/public_html/diagnostics/e3sm_to_cmip_data/cmip6-cmor-tables/Tables/\",\r\n    \"--user-metadata\",\r\n    \"/lcrc/group/e3sm/public_html/diagnostics/e3sm_to_cmip_data/user_metadata.json\",\r\n    \"--serial\",\r\n]\r\n\r\nrun = E3SMtoCMIP(args)\r\n\r\nrun.run()\r\n\r\n```\r\n\r\n### Log Output (Success)\r\n```python\r\n2023-11-27 22:34:27,673 [INFO]: __main__.py(__init__:142) >> --------------------------------------\r\n2023-11-27 22:34:27,673 [INFO]: __main__.py(__init__:142) >> --------------------------------------\r\n2023-11-27 22:34:27,673_673:INFO:__init__:--------------------------------------\r\n2023-11-27 22:34:27,674 [INFO]: __main__.py(__init__:143) >> | E3SM to CMIP Configuration\r\n2023-11-27 22:34:27,674 [INFO]: __main__.py(__init__:143) >> | E3SM to CMIP Configuration\r\n2023-11-27 22:34:27,674_674:INFO:__init__:| E3SM to CMIP Configuration\r\n2023-11-27 22:34:27,675 [INFO]: __main__.py(__init__:144) >> --------------------------------------\r\n2023-11-27 22:34:27,675 [INFO]: __main__.py(__init__:144) >> --------------------------------------\r\n2023-11-27 22:34:27,675_675:INFO:__init__:--------------------------------------\r\n2023-11-27 22:34:27,675 [INFO]: __main__.py(__init__:145) >>     * var_list='['lai']'\r\n2023-11-27 22:34:27,675 [INFO]: __main__.py(__init__:145) >>     * var_list='['lai']'\r\n2023-11-27 22:34:27,675_675:INFO:__init__:    * var_list='['lai']'\r\n2023-11-27 22:34:27,676 [INFO]: __main__.py(__init__:146) >>     * input_path='/lcrc/group/e3sm/ac.zhang40/tests/20231012.v3alpha04_trigrid_bgc.piControl.chrysalis/post/lnd/native/ts/monthly/50yr'\r\n2023-11-27 22:34:27,676 [INFO]: __main__.py(__init__:146) >>     * input_path='/lcrc/group/e3sm/ac.zhang40/tests/20231012.v3alpha04_trigrid_bgc.piControl.chrysalis/post/lnd/native/ts/monthly/50yr'\r\n2023-11-27 22:34:27,676_676:INFO:__init__:    * input_path='/lcrc/group/e3sm/ac.zhang40/tests/20231012.v3alpha04_trigrid_bgc.piControl.chrysalis/post/lnd/native/ts/monthly/50yr'\r\n2023-11-27 22:34:27,677 [INFO]: __main__.py(__init__:147) >>     * output_path='./'\r\n2023-11-27 22:34:27,677 [INFO]: __main__.py(__init__:147) >>     * output_path='./'\r\n2023-11-27 22:34:27,677_677:INFO:__init__:    * output_path='./'\r\n2023-11-27 22:34:27,677 [INFO]: __main__.py(__init__:148) >>     * precheck_path='None'\r\n2023-11-27 22:34:27,677 [INFO]: __main__.py(__init__:148) >>     * precheck_path='None'\r\n2023-11-27 22:34:27,677_677:INFO:__init__:    * precheck_path='None'\r\n2023-11-27 22:34:27,678 [INFO]: __main__.py(__init__:149) >>     * freq='mon'\r\n2023-11-27 22:34:27,678 [INFO]: __main__.py(__init__:149) >>     * freq='mon'\r\n2023-11-27 22:34:27,678_678:INFO:__init__:    * freq='mon'\r\n2023-11-27 22:34:27,679 [INFO]: __main__.py(__init__:150) >>     * realm='atm'\r\n2023-11-27 22:34:27,679 [INFO]: __main__.py(__init__:150) >>     * realm='atm'\r\n2023-11-27 22:34:27,679_679:INFO:__init__:    * realm='atm'\r\n2023-11-27 22:34:27,679 [INFO]: __main__.py(__init__:151) >>     * Writing log output file to: logs/20231127_223427_670596\r\n2023-11-27 22:34:27,679 [INFO]: __main__.py(__init__:151) >>     * Writing log output file to: logs/20231127_223427_670596\r\n2023-11-27 22:34:27,679_679:INFO:__init__:    * Writing log output file to: logs/20231127_223427_670596\r\n2023-11-27 22:34:59,714 [INFO]: __main__.py(_get_handlers:220) >> --------------------------------------\r\n2023-11-27 22:34:59,714 [INFO]: __main__.py(_get_handlers:220) >> --------------------------------------\r\n2023-11-27 22:34:59,714_714:INFO:_get_handlers:--------------------------------------\r\n2023-11-27 22:34:59,715 [INFO]: __main__.py(_get_handlers:221) >> | Derived CMIP6 Variable Handlers\r\n2023-11-27 22:34:59,715 [INFO]: __main__.py(_get_handlers:221) >> | Derived CMIP6 Variable Handlers\r\n2023-11-27 22:34:59,715_715:INFO:_get_handlers:| Derived CMIP6 Variable Handlers\r\n2023-11-27 22:34:59,716 [INFO]: __main__.py(_get_handlers:222) >> --------------------------------------\r\n2023-11-27 22:34:59,716 [INFO]: __main__.py(_get_handlers:222) >> --------------------------------------\r\n2023-11-27 22:34:59,716_716:INFO:_get_handlers:--------------------------------------\r\n2023-11-27 22:34:59,717 [INFO]: __main__.py(_get_handlers:224) >>     * 'lai' -> ['LAISHA', 'LAISUN']\r\n2023-11-27 22:34:59,717 [INFO]: __main__.py(_get_handlers:224) >>     * 'lai' -> ['LAISHA', 'LAISUN']\r\n2023-11-27 22:34:59,717_717:INFO:_get_handlers:    * 'lai' -> ['LAISHA', 'LAISUN']\r\n2023-11-27 22:34:59,757 [INFO]: __main__.py(_run:737) >> --------------------------------------\r\n2023-11-27 22:34:59,757 [INFO]: __main__.py(_run:737) >> --------------------------------------\r\n2023-11-27 22:34:59,757_757:INFO:_run:--------------------------------------\r\n2023-11-27 22:34:59,758 [INFO]: __main__.py(_run:738) >> | Running E3SM to CMIP in Serial\r\n2023-11-27 22:34:59,758 [INFO]: __main__.py(_run:738) >> | Running E3SM to CMIP in Serial\r\n2023-11-27 22:34:59,758_758:INFO:_run:| Running E3SM to CMIP in Serial\r\n2023-11-27 22:34:59,759 [INFO]: __main__.py(_run:739) >> --------------------------------------\r\n2023-11-27 22:34:59,759 [INFO]: __main__.py(_run:739) >> --------------------------------------\r\n2023-11-27 22:34:59,759_759:INFO:_run:--------------------------------------\r\n2023-11-27 22:34:59,765 [INFO]: __main__.py(_run_serial:796) >> Trying to CMORize with handler: {'name': 'lai', 'units': '1', 'raw_variables': ['LAISHA', 'LAISUN'], 'table': 'CMIP6_Lmon.json', 'unit_conversion': None, 'formula': 'LAISHA + LAISUN', 'formula_method': <function lai at 0x1550b83b60c0>, 'positive': None, 'levels': None, 'output_data': None, 'method': <bound method VarHandler.cmorize of <e3sm_to_cmip.cmor_handlers.handler.VarHandler object at 0x1550b80f0350>>}\r\n2023-11-27 22:34:59,765 [INFO]: __main__.py(_run_serial:796) >> Trying to CMORize with handler: {'name': 'lai', 'units': '1', 'raw_variables': ['LAISHA', 'LAISUN'], 'table': 'CMIP6_Lmon.json', 'unit_conversion': None, 'formula': 'LAISHA + LAISUN', 'formula_method': <function lai at 0x1550b83b60c0>, 'positive': None, 'levels': None, 'output_data': None, 'method': <bound method VarHandler.cmorize of <e3sm_to_cmip.cmor_handlers.handler.VarHandler object at 0x1550b80f0350>>}\r\n2023-11-27 22:34:59,765_765:INFO:_run_serial:Trying to CMORize with handler: {'name': 'lai', 'units': '1', 'raw_variables': ['LAISHA', 'LAISUN'], 'table': 'CMIP6_Lmon.json', 'unit_conversion': None, 'formula': 'LAISHA + LAISUN', 'formula_method': <function lai at 0x1550b83b60c0>, 'positive': None, 'levels': None, 'output_data': None, 'method': <bound method VarHandler.cmorize of <e3sm_to_cmip.cmor_handlers.handler.VarHandler object at 0x1550b80f0350>>}\r\n2023-11-27 22:34:59,766 [INFO]: handler.py(cmorize:209) >> lai: Starting CMORizing\r\n2023-11-27 22:34:59,766 [INFO]: handler.py(cmorize:209) >> lai: Starting CMORizing\r\n2023-11-27 22:34:59,766_766:INFO:cmorize:lai: Starting CMORizing\r\n2023-11-27 22:34:59,973 [INFO]: handler.py(_setup_cmor_module:323) >> lai: CMOR setup complete\r\n2023-11-27 22:34:59,973 [INFO]: handler.py(_setup_cmor_module:323) >> lai: CMOR setup complete\r\n2023-11-27 22:34:59,973_973:INFO:_setup_cmor_module:lai: CMOR setup complete\r\n2023-11-27 22:34:59,975 [INFO]: handler.py(cmorize:239) >> lai: loading E3SM variables dict_keys(['LAISHA', 'LAISUN'])\r\n2023-11-27 22:34:59,975 [INFO]: handler.py(cmorize:239) >> lai: loading E3SM variables dict_keys(['LAISHA', 'LAISUN'])\r\n2023-11-27 22:34:59,975_975:INFO:cmorize:lai: loading E3SM variables dict_keys(['LAISHA', 'LAISUN'])\r\n2023-11-27 22:35:03,464 [INFO]: handler.py(cmorize:248) >> lai: creating CMOR variable with CMOR axis objects.\r\n2023-11-27 22:35:03,464 [INFO]: handler.py(cmorize:248) >> lai: creating CMOR variable with CMOR axis objects.\r\n2023-11-27 22:35:03,464_464:INFO:cmorize:lai: creating CMOR variable with CMOR axis objects.\r\n2023-11-27 22:35:05,276 [INFO]: handler.py(_cmor_write:648) >> lai: time span 18250.0 - 36500.0\r\n2023-11-27 22:35:05,276 [INFO]: handler.py(_cmor_write:648) >> lai: time span 18250.0 - 36500.0\r\n2023-11-27 22:35:05,276_276:INFO:_cmor_write:lai: time span 18250.0 - 36500.0\r\n2023-11-27 22:35:05,277 [INFO]: handler.py(_cmor_write:652) >> lai: Writing variable to file...\r\n2023-11-27 22:35:05,277 [INFO]: handler.py(_cmor_write:652) >> lai: Writing variable to file...\r\n2023-11-27 22:35:05,277_277:INFO:_cmor_write:lai: Writing variable to file...\r\n2023-11-27 22:35:14,245 [INFO]: __main__.py(_run_serial:821) >> Finished lai, 1/1 jobs complete\r\n2023-11-27 22:35:14,245 [INFO]: __main__.py(_run_serial:821) >> Finished lai, 1/1 jobs complete\r\n2023-11-27 22:35:14,245_245:INFO:_run_serial:Finished lai, 1/1 jobs complete\r\n2023-11-27 22:35:14,246 [INFO]: __main__.py(_run_serial:836) >> 1 of 1 handlers complete\r\n2023-11-27 22:35:14,246 [INFO]: __main__.py(_run_serial:836) >> 1 of 1 handlers complete\r\n2023-11-27 22:35:14,246_246:INFO:_run_serial:1 of 1 handlers complete\r\n```\r\n\r\n## Checklist\r\n\r\n- [x] My code follows the style guidelines of this project\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings\r\n- [x] Any dependent changes have been merged and published in downstream modules\r\n\r\nIf applicable:\r\n\r\n- [x] New and existing unit tests pass with my changes (locally and CI/CD build)\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have noted that this is a breaking change for a major release (fix or feature that would cause existing functionality to not work as expected)\r\n",
    "repository_url": "https://api.github.com/repos/E3SM-Project/e3sm_to_cmip",
    "repository_clone_url": "https://github.com/E3SM-Project/e3sm_to_cmip",
    "repository_name": "e3sm_to_cmip",
    "diff_url": "https://github.com/E3SM-Project/e3sm_to_cmip/pull/228.diff",
    "merged_at": "2023-12-07T22:29:20Z"
  },
  {
    "Pull request index": 10,
    "PR title": "Get ROCK image right tag considering the latest merged rock files",
    "PR URL": "https://github.com/canonical/operator-workflows/pull/217",
    "created_at": "2023-11-27T19:46:55Z",
    "updated_at": "2023-12-01T11:32:14Z",
    "closed_at": "2023-12-01T11:32:13Z",
    "body": "Applicable spec: <link>\r\n\r\n### Overview\r\n\r\nWhat happened in Synapse:\r\n\r\n24 Nov: I submitted a WIP PR that changes the ROCK images https://github.com/canonical/synapse-operator/pull/111\r\n27 Nov: Publish to Edge workflow sucessfully ran with merged changes (update jsonschema)\r\n27 Nov: I refreshed Synapse charm in production to apply the fix regarding nginx pebble ready event (23 Nov) + this last one regarding jsonschema\r\nFor my huge surprise: Synapse image is running the latest Synapse version as was changed in the WIP PR\r\n\r\n### Rationale\r\n\r\nMake publish charm get the latest image from the latest merged PR and not the latest uploaded.\r\n\r\n### Workflow Changes\r\n\r\n<!-- Any high level changes to workflows and why -->\r\n\r\n### Checklist\r\n\r\n- [X] The [contributing guide](https://github.com/canonical/is-charms-contributing-guide) was applied\r\n- [X] The PR is tagged with appropriate label (`urgent`, `trivial`, `complex`)\r\n\r\n<!-- Explanation for any unchecked items above -->\r\n",
    "repository_url": "https://api.github.com/repos/canonical/operator-workflows",
    "repository_clone_url": "https://github.com/canonical/operator-workflows",
    "repository_name": "operator-workflows",
    "diff_url": "https://github.com/canonical/operator-workflows/pull/217.diff",
    "merged_at": "2023-12-01T11:32:13Z"
  },
  {
    "Pull request index": 11,
    "PR title": "[BugFix] Fix deepcopy of TensorDictParams",
    "PR URL": "https://github.com/pytorch/tensordict/pull/580",
    "created_at": "2023-11-27T10:28:26Z",
    "updated_at": "2023-11-27T10:37:24Z",
    "closed_at": "2023-11-27T10:28:33Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/580.diff",
    "merged_at": "2023-11-27T10:28:33Z"
  },
  {
    "Pull request index": 12,
    "PR title": "[BugFix] No fallback on `TensorDictModule.__getattr__` for private attributes",
    "PR URL": "https://github.com/pytorch/tensordict/pull/579",
    "created_at": "2023-11-27T09:49:34Z",
    "updated_at": "2023-11-27T09:58:48Z",
    "closed_at": "2023-11-27T09:51:44Z",
    "body": "## Description\r\n\r\nCurrently, `TensorDictModule.__getattr__` falls back on the module `__getattr__` if the attribute cannot be found. For `deepcopy`, this causes `__deepcopy__` to return the module within, not the TDModule container copy.\r\nWe solve this by excluding any private attribute from fallback.\r\n\r\nRelated issue:\r\nhttps://github.com/pytorch/rl/issues/1576#issuecomment-1826899930",
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/579.diff",
    "merged_at": "2023-11-27T09:51:44Z"
  },
  {
    "Pull request index": 13,
    "PR title": "Fix ST2 Client for Windows Clients",
    "PR URL": "https://github.com/StackStorm/st2/pull/6071",
    "created_at": "2023-11-26T08:16:11Z",
    "updated_at": "2023-11-28T13:20:25Z",
    "closed_at": "2023-11-28T13:20:25Z",
    "body": "We have try to rollout the st2client on the Windows 10/11 clients of our StackStorm users. But because PWD only exist on Unix Based Operation System it failed. \r\n\r\n",
    "repository_url": "https://api.github.com/repos/StackStorm/st2",
    "repository_clone_url": "https://github.com/StackStorm/st2",
    "repository_name": "st2",
    "diff_url": "https://github.com/StackStorm/st2/pull/6071.diff",
    "merged_at": "2023-11-28T13:20:24Z"
  },
  {
    "Pull request index": 14,
    "PR title": "java: Fix regression _find_rw_exec_dir() failing to handle ro dirs",
    "PR URL": "https://github.com/Granulate/gprofiler/pull/860",
    "created_at": "2023-11-24T20:45:30Z",
    "updated_at": "2023-11-29T14:41:14Z",
    "closed_at": "2023-11-29T14:41:13Z",
    "body": "Fixes a regression from https://github.com/Granulate/gprofiler/commit/6360449252793ad59802a3c09fde297646529b7d, and improves the tests\r\nso we'd catch it next time :)",
    "repository_url": "https://api.github.com/repos/Granulate/gprofiler",
    "repository_clone_url": "https://github.com/Granulate/gprofiler",
    "repository_name": "gprofiler",
    "diff_url": "https://github.com/Granulate/gprofiler/pull/860.diff",
    "merged_at": "2023-11-29T14:41:13Z"
  },
  {
    "Pull request index": 15,
    "PR title": "[BugFix] _FileHandler for windows",
    "PR URL": "https://github.com/pytorch/tensordict/pull/577",
    "created_at": "2023-11-24T14:39:57Z",
    "updated_at": "2023-11-24T14:48:25Z",
    "closed_at": "2023-11-24T14:40:19Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/577.diff",
    "merged_at": "2023-11-24T14:40:19Z"
  },
  {
    "Pull request index": 16,
    "PR title": "[BugFix] Compatibility with missing _global_parameter_registration_hooks",
    "PR URL": "https://github.com/pytorch/tensordict/pull/574",
    "created_at": "2023-11-24T11:16:49Z",
    "updated_at": "2023-11-24T11:25:29Z",
    "closed_at": "2023-11-24T11:17:32Z",
    "body": "Older pytorch versions lack the `_global_parameter_registration_hooks` function.\r\nThis PR makes it accessory.",
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/574.diff",
    "merged_at": "2023-11-24T11:17:32Z"
  },
  {
    "Pull request index": 17,
    "PR title": "Error handling outside of a foundry project",
    "PR URL": "https://github.com/runtimeverification/kontrol/pull/204",
    "created_at": "2023-11-24T07:45:59Z",
    "updated_at": "2023-12-04T14:42:34Z",
    "closed_at": "2023-12-04T14:42:33Z",
    "body": "Fixes: https://github.com/runtimeverification/kontrol/issues/93\r\n\r\nGracefully ends execution when `kontrol` is used outside of a Foundry project.",
    "repository_url": "https://api.github.com/repos/runtimeverification/kontrol",
    "repository_clone_url": "https://github.com/runtimeverification/kontrol",
    "repository_name": "kontrol",
    "diff_url": "https://github.com/runtimeverification/kontrol/pull/204.diff",
    "merged_at": "2023-12-04T14:42:32Z"
  },
  {
    "Pull request index": 18,
    "PR title": "[BugFix] Graceful attribute error exit in TensorDictParams",
    "PR URL": "https://github.com/pytorch/tensordict/pull/571",
    "created_at": "2023-11-23T17:50:51Z",
    "updated_at": "2023-11-23T18:00:14Z",
    "closed_at": "2023-11-23T17:52:36Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/pytorch/tensordict",
    "repository_clone_url": "https://github.com/pytorch/tensordict",
    "repository_name": "tensordict",
    "diff_url": "https://github.com/pytorch/tensordict/pull/571.diff",
    "merged_at": "2023-11-23T17:52:36Z"
  },
  {
    "Pull request index": 19,
    "PR title": "Feature/gsk 2189 internal ml worker cant start",
    "PR URL": "https://github.com/Giskard-AI/giskard/pull/1631",
    "created_at": "2023-11-23T11:16:36Z",
    "updated_at": "2023-11-23T12:20:54Z",
    "closed_at": "2023-11-23T12:20:53Z",
    "body": "## Description\r\n\r\n<!-- Add a more detailed description of the changes if needed. -->\r\n\r\n## Related Issue\r\n\r\n<!-- If your PR refers to a related issue, link it here. -->\r\n\r\n## Type of Change\r\n\r\n<!-- Mark with an `x` all the checkboxes that apply (like `[x]`) -->\r\n\r\n- [ ] \ud83d\udcda Examples / docs / tutorials / dependencies update\r\n- [ ] \ud83d\udd27 Bug fix (non-breaking change which fixes an issue)\r\n- [ ] \ud83e\udd42 Improvement (non-breaking change which improves an existing feature)\r\n- [ ] \ud83d\ude80 New feature (non-breaking change which adds functionality)\r\n- [ ] \ud83d\udca5 Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] \ud83d\udd10 Security fix\r\n\r\n## Checklist\r\n\r\n<!-- Mark with an `x` all the checkboxes that apply (like `[x]`) -->\r\n\r\n- [ ] I've read the [`CODE_OF_CONDUCT.md`](https://github.com/Giskard-AI/ai-inspector/blob/master/CODE_OF_CONDUCT.md) document.\r\n- [ ] I've read the [`CONTRIBUTING.md`](https://github.com/Giskard-AI/ai-inspector/blob/master/CONTRIBUTING.md) guide.\r\n- [ ] I've updated the code style using `make codestyle`.\r\n- [ ] I've written tests for all new methods and classes that I created.\r\n- [ ] I've written the docstring in Google format for all the methods and classes that I used.\r\n",
    "repository_url": "https://api.github.com/repos/Giskard-AI/giskard",
    "repository_clone_url": "https://github.com/Giskard-AI/giskard",
    "repository_name": "giskard",
    "diff_url": "https://github.com/Giskard-AI/giskard/pull/1631.diff",
    "merged_at": "2023-11-23T12:20:53Z"
  },
  {
    "Pull request index": 20,
    "PR title": "ISD-1307 Update permission when mounting storage",
    "PR URL": "https://github.com/canonical/jenkins-k8s-operator/pull/63",
    "created_at": "2023-11-20T00:15:52Z",
    "updated_at": "2023-11-21T15:45:04Z",
    "closed_at": "2023-11-21T15:45:02Z",
    "body": "### Overview\r\nFix storage mount permission issue on certain environments\r\n\r\n### Checklist\r\n\r\n- [x] The [charm style guide](https://juju.is/docs/sdk/styleguide) was applied\r\n- [x] The [contributing guide](https://github.com/canonical/is-charms-contributing-guide) was applied\r\n- [x] The changes are compliant with [ISD054 - Managing Charm Complexity](https://discourse.charmhub.io/t/specification-isd014-managing-charm-complexity/11619)\r\n- [x] The documentation is generated using `src-docs`\r\n- [x] The documentation for charmhub is updated.\r\n- [x] The PR is tagged with appropriate label (`urgent`, `trivial`, `complex`)\r\n\r\n<!-- Explanation for any unchecked items above -->\r\n",
    "repository_url": "https://api.github.com/repos/canonical/jenkins-k8s-operator",
    "repository_clone_url": "https://github.com/canonical/jenkins-k8s-operator",
    "repository_name": "jenkins-k8s-operator",
    "diff_url": "https://github.com/canonical/jenkins-k8s-operator/pull/63.diff",
    "merged_at": "2023-11-21T15:45:02Z"
  },
  {
    "Pull request index": 21,
    "PR title": "Log ignored exception details to debug log",
    "PR URL": "https://github.com/ansible/ansible-lint/pull/3900",
    "created_at": "2023-11-16T07:53:46Z",
    "updated_at": "2023-11-27T13:23:18Z",
    "closed_at": "2023-11-27T13:23:18Z",
    "body": "This allows the user to see the exception stack trace by running in verbose mode.\r\n\r\nExample:\r\n\r\n```\r\nDEBUG    Running rule yaml\r\nDEBUG    Running rule args\r\nWARNING  Ignored exception from ArgsRule.<bound method AnsibleLintRule.matchtasks of args: Validating module arguments.> while processing roles/alertmanager/tasks/main.yml (tasks): No module named 'distutils'\r\nDEBUG    Ignored exception details\r\nTraceback (most recent call last):\r\n  File \"/home/bluecmd/work/sonix-ansible/ansible/lib64/python3.12/site-packages/ansiblelint/_internal/rules.py\", line 93, in getmatches\r\n    matches.extend(method(file))\r\n                   ^^^^^^^^^^^^\r\n  File \"/home/bluecmd/work/sonix-ansible/ansible/lib64/python3.12/site-packages/ansiblelint/rules/__init__.py\", line 177, in matchtasks\r\n    result = self.matchtask(task, file=file)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/bluecmd/work/sonix-ansible/ansible/lib64/python3.12/site-packages/ansiblelint/rules/args.py\", line 159, in matchtask\r\n    spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 994, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n  File \"/home/bluecmd/.ansible/collections/ansible_collections/ansible/posix/plugins/modules/firewalld.py\", line 216, in <module>\r\n    from ansible_collections.ansible.posix.plugins.module_utils.firewalld import FirewallTransaction, fw_offline\r\n  File \"/home/bluecmd/work/sonix-ansible/ansible/lib64/python3.12/site-packages/ansible/utils/collection_loader/_collection_finder.py\", line 594, in exec_module\r\n    exec(code_obj, module.__dict__)\r\n  File \"/home/bluecmd/.ansible/collections/ansible_collections/ansible/posix/plugins/module_utils/firewalld.py\", line 11, in <module>\r\n    from distutils.version import LooseVersion\r\nModuleNotFoundError: No module named 'distutils'\r\nDEBUG    Running rule avoid-implicit\r\nDEBUG    Running rule command-instead-of-module\r\n```",
    "repository_url": "https://api.github.com/repos/ansible/ansible-lint",
    "repository_clone_url": "https://github.com/ansible/ansible-lint",
    "repository_name": "ansible-lint",
    "diff_url": "https://github.com/ansible/ansible-lint/pull/3900.diff",
    "merged_at": "2023-11-27T13:23:17Z"
  },
  {
    "Pull request index": 22,
    "PR title": "fix scipy, fix pip/apt error",
    "PR URL": "https://github.com/uwsbel/autonomy-research-testbed/pull/101",
    "created_at": "2023-11-14T14:24:47Z",
    "updated_at": "2023-11-15T03:59:22Z",
    "closed_at": "2023-11-15T03:59:18Z",
    "body": "title, #100 ",
    "repository_url": "https://api.github.com/repos/uwsbel/autonomy-research-testbed",
    "repository_clone_url": "https://github.com/uwsbel/autonomy-research-testbed",
    "repository_name": "autonomy-research-testbed",
    "diff_url": "https://github.com/uwsbel/autonomy-research-testbed/pull/101.diff",
    "merged_at": "2023-11-15T03:59:18Z"
  },
  {
    "Pull request index": 23,
    "PR title": "Fix certificates globbing from relative paths for `keychain add-certificates`",
    "PR URL": "https://github.com/codemagic-ci-cd/cli-tools/pull/374",
    "created_at": "2023-11-13T10:44:19Z",
    "updated_at": "2023-11-13T11:51:50Z",
    "closed_at": "2023-11-13T11:51:50Z",
    "body": "It is possible to specify custom certificate paths or path patterns for action `keychain add-certificates` via CLI option `--certificate`. As this option accepts either path literals, or a glob patterns to match certificates, then relative reference `.` to current directory should also be an acceptable input. This however results in an error when globbing matches:\r\n\r\n```python\r\n>>> list(Path().glob('.'))\r\nTraceback (most recent call last):\r\n  File \"/Users/priit/development/nevercode/cli-tools/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-23-b1f87bcdf599>\", line 1, in <cell line: 0>\r\n    list(Path().glob('.'))\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/pathlib.py\", line 1094, in glob\r\n    selector = _make_selector(tuple(pattern_parts), self._flavour, case_sensitive)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/priit/.pyenv/versions/3.12.0/lib/python3.12/pathlib.py\", line 83, in _make_selector\r\n    pat = pattern_parts[0]\r\n          ~~~~~~~~~~~~~^^^\r\nIndexError: tuple index out of range\r\n```\r\n\r\nTo overcome that limitation, just resolve the relative path pattern before attempting glob search. Then the path becomes absolute which can be safely globbed.\r\n\r\n**Updated actions:**\r\n- `keychain add-certificates`",
    "repository_url": "https://api.github.com/repos/codemagic-ci-cd/cli-tools",
    "repository_clone_url": "https://github.com/codemagic-ci-cd/cli-tools",
    "repository_name": "cli-tools",
    "diff_url": "https://github.com/codemagic-ci-cd/cli-tools/pull/374.diff",
    "merged_at": "2023-11-13T11:51:50Z"
  },
  {
    "Pull request index": 24,
    "PR title": "[FIX]: Fix `_check_fsl()`",
    "PR URL": "https://github.com/juaml/junifer/pull/272",
    "created_at": "2023-10-31T14:50:55Z",
    "updated_at": "2023-11-07T11:16:46Z",
    "closed_at": "2023-11-07T11:10:51Z",
    "body": "* [x] description of feature/fix\n* [x] tests added/passed\n* [x] add an entry for the latest changes\n\nThis PR fixes `_check_fsl()` by replacing 0 with 1 as the return code for successful FSL commands.",
    "repository_url": "https://api.github.com/repos/juaml/junifer",
    "repository_clone_url": "https://github.com/juaml/junifer",
    "repository_name": "junifer",
    "diff_url": "https://github.com/juaml/junifer/pull/272.diff",
    "merged_at": "2023-11-07T11:10:51Z"
  },
  {
    "Pull request index": 25,
    "PR title": "Handle nodata data adapter",
    "PR URL": "https://github.com/Deltares/hydromt/pull/621",
    "created_at": "2023-10-27T14:05:15Z",
    "updated_at": "2023-10-30T08:42:25Z",
    "closed_at": "2023-10-30T08:42:24Z",
    "body": "## Issue addressed\r\nFixes #584 \r\n\r\n## Explanation\r\n`DataAdapter._slice_data` and `DataCatalog.get_<data type>` now have a `handle_nodata` argument.\r\n\r\n## Checklist\r\n- [x] Updated tests or added new tests\r\n- [x] Branch is up to date with `main`\r\n- [x] Tests & pre-commit hooks pass\r\n- [x] Updated documentation if needed\r\n- [x] Updated changelog.rst if needed\r\n\r\n## Additional Notes (optional)\r\n`DataAdapter.get_data` not yet implemented with this feature, but defaults still maintain the same behaviour. Only the error type returned is different. I still propose to refactor the DataAdapter vs. DataCatalog relation, so that we can change this behaviour in one place only.",
    "repository_url": "https://api.github.com/repos/Deltares/hydromt",
    "repository_clone_url": "https://github.com/Deltares/hydromt",
    "repository_name": "hydromt",
    "diff_url": "https://github.com/Deltares/hydromt/pull/621.diff",
    "merged_at": "2023-10-30T08:42:24Z"
  },
  {
    "Pull request index": 26,
    "PR title": "Fix entrypoint path in Dockerfile for src directory change",
    "PR URL": "https://github.com/ASFHyP3/hyp3-autorift/pull/238",
    "created_at": "2023-10-20T22:25:35Z",
    "updated_at": "2023-10-20T22:37:53Z",
    "closed_at": "2023-10-20T22:37:52Z",
    "body": "Missed a path change in the docker file. If I pull the latest and over ride the entrypoint it runs just fine:\r\n\r\n```shell\r\n$ docker pull ghcr.io/asfhyp3/hyp3-autorift:test\r\n$ docker run ghcr.io/asfhyp3/hyp3-autorift:test --help\r\ndocker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: \"/hyp3-autorift/hyp3_autorift/etc/entrypoint.sh\": stat /hyp3-autorift/hyp3_autorift/etc/entrypoint.sh: no such file or directory: unknown.\r\n```\r\n```shell\r\n$  docker run --entrypoint /hyp3-autorift/src/hyp3_autorift/etc/entrypoint.sh ghcr.io/asfhyp3/hyp3-autorift:test --help\r\n/opt/conda/envs/hyp3-autorift/lib/python3.9/site-packages/hyp3_autorift/__main__.py:35: UserWarning: Earthdata credentials must be present as environment variables, or in your netrc.\r\n  warnings.warn('Earthdata credentials must be present as environment variables, or in your netrc.', UserWarning)\r\nThis is the Open Source version of ISCE.\r\nSome of the workflows depend on a separate licensed package.\r\nTo obtain the licensed package, please make a request for ISCE\r\nthrough the website: https://download.jpl.nasa.gov/ops/request/index.cfm.\r\nAlternatively, if you are a member, or can become a member of WinSAR\r\nyou may be able to obtain access to a version of the licensed sofware at\r\nhttps://winsar.unavco.org/software/isce\r\n2023-10-20 22:32:26,233 - matplotlib - DEBUG - matplotlib data path: /opt/conda/envs/hyp3-autorift/lib/python3.9/site-packages/matplotlib/mpl-data\r\n2023-10-20 22:32:26,236 - matplotlib - DEBUG - CONFIGDIR=/home/conda/.config/matplotlib\r\n2023-10-20 22:32:26,236 - matplotlib - DEBUG - interactive is False\r\n2023-10-20 22:32:26,236 - matplotlib - DEBUG - platform is linux\r\n2023-10-20 22:32:26,259 - matplotlib - DEBUG - CACHEDIR=/home/conda/.cache/matplotlib\r\n2023-10-20 22:32:26,259 - matplotlib.font_manager - DEBUG - font search path [PosixPath('/opt/conda/envs/hyp3-autorift/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/ttf'), PosixPath('/opt/conda/envs/hyp3-autorift/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/afm'), PosixPath('/opt/conda/envs/hyp3-autorift/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts')]\r\n2023-10-20 22:32:26,334 - matplotlib.font_manager - INFO - generated new fontManager\r\nusage: hyp3_autorift [-h] [--bucket BUCKET] [--bucket-prefix BUCKET_PREFIX]\r\n                     [--parameter-file PARAMETER_FILE]\r\n                     [--naming-scheme {ITS_LIVE_OD,ITS_LIVE_PROD,ASF}]\r\n                     granules [granules ...]\r\n\r\npositional arguments:\r\n  granules              Granule pair to process\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  --bucket BUCKET       AWS bucket to upload product files to (default: None)\r\n  --bucket-prefix BUCKET_PREFIX\r\n                        AWS prefix (location in bucket) to add to product\r\n                        files (default: )\r\n  --parameter-file PARAMETER_FILE\r\n                        Shapefile for determining the correct search\r\n                        parameters by geographic location. Path to shapefile\r\n                        must be understood by GDAL (default:\r\n                        /vsicurl/http://its-live-data.s3.amazonaws.com/autorif\r\n                        t_parameters/v001/autorift_landice_0120m.shp)\r\n  --naming-scheme {ITS_LIVE_OD,ITS_LIVE_PROD,ASF}\r\n                        Naming scheme to use for product files (default:\r\n                        ITS_LIVE_OD)\r\n\r\n```\r\n",
    "repository_url": "https://api.github.com/repos/ASFHyP3/hyp3-autorift",
    "repository_clone_url": "https://github.com/ASFHyP3/hyp3-autorift",
    "repository_name": "hyp3-autorift",
    "diff_url": "https://github.com/ASFHyP3/hyp3-autorift/pull/238.diff",
    "merged_at": "2023-10-20T22:37:52Z"
  },
  {
    "Pull request index": 27,
    "PR title": "More robust Windows launch command for Watchdog",
    "PR URL": "https://github.com/ansys/pyfluent/pull/2167",
    "created_at": "2023-10-20T19:41:12Z",
    "updated_at": "2023-10-24T13:58:43Z",
    "closed_at": "2023-10-24T13:58:42Z",
    "body": "Attempting to make the command as explicit as possible, to see if this error, that only occurs in some systems, and that I have been unable to reproduce, is finally resolved without requiring the user to change anything about their system\r\n\r\nChanging from command list, which seems to have behavior that can be system dependent on Windows, to a command string, which should be more robust",
    "repository_url": "https://api.github.com/repos/ansys/pyfluent",
    "repository_clone_url": "https://github.com/ansys/pyfluent",
    "repository_name": "pyfluent",
    "diff_url": "https://github.com/ansys/pyfluent/pull/2167.diff",
    "merged_at": "2023-10-24T13:58:42Z"
  },
  {
    "Pull request index": 28,
    "PR title": "Increasing Speed of the code and the functionality",
    "PR URL": "https://github.com/ansible/ansible/pull/82028",
    "created_at": "2023-10-19T15:46:52Z",
    "updated_at": "2023-11-16T14:00:07Z",
    "closed_at": "2023-10-19T20:04:23Z",
    "body": "##### SUMMARY\r\n\r\n<!--- Describe the change below, including rationale and design decisions -->\r\n\r\n<!--- HINT: Include \"Fixes #nnn\" if you are fixing an existing issue -->\r\n\r\n##### ISSUE TYPE\r\n\r\n<!--- Pick one below and delete the rest -->\r\n\r\n- Bugfix Pull Request\r\n- Docs Pull Request\r\n- Feature Pull Request\r\n- Test Pull Request\r\n\r\n##### ADDITIONAL INFORMATION\r\n\r\n<!--- Include additional information to help people understand the change here -->\r\n<!--- A step-by-step reproduction of the problem is helpful if there is no related issue -->\r\n\r\n<!--- Paste verbatim command output below, e.g. before and after your change -->\r\n\r\n```paste below\r\n\r\n```\r\n",
    "repository_url": "https://api.github.com/repos/ansible/ansible",
    "repository_clone_url": "https://github.com/ansible/ansible",
    "repository_name": "ansible",
    "diff_url": "https://github.com/ansible/ansible/pull/82028.diff",
    "merged_at": null
  },
  {
    "Pull request index": 29,
    "PR title": "fix(cryptocom): postOnly order [ci deploy]",
    "PR URL": "https://github.com/ccxt/ccxt/pull/19591",
    "created_at": "2023-10-16T15:52:00Z",
    "updated_at": "2023-10-16T16:50:13Z",
    "closed_at": "2023-10-16T16:50:13Z",
    "body": null,
    "repository_url": "https://api.github.com/repos/ccxt/ccxt",
    "repository_clone_url": "https://github.com/ccxt/ccxt",
    "repository_name": "ccxt",
    "diff_url": "https://github.com/ccxt/ccxt/pull/19591.diff",
    "merged_at": "2023-10-16T16:50:13Z"
  },
  {
    "Pull request index": 30,
    "PR title": "analytics: fix mac not sending reports",
    "PR URL": "https://github.com/iterative/dvc/pull/10026",
    "created_at": "2023-10-16T14:58:37Z",
    "updated_at": "2023-10-17T17:37:55Z",
    "closed_at": "2023-10-16T20:28:29Z",
    "body": "Not sure if this is the best approach to fix the issue, but currently we [do not seem to be sending analytics reports for mac since March](https://iterativeai.slack.com/archives/CB41NAL8H/p1697464559356029?thread_ts=1697200360.717249&cid=CB41NAL8H). I have tested and found that it seems to be some combination of forking and the `_popen` method used. Analytics get sent successfully if I either:\r\n1. Drop all the forking logic, OR\r\n2. Call `main` like it does for linux.\r\n\r\nHere I dropped all the forking and conditions here and just use `_popen` directly. This successfully sends reports for me, and I'm not sure why we need forking here since it should happen in a separate, non-blocking process when using `_popen` (and dropping `.communicate()`). \r\n\r\nNot sure if I miss some context for why forking or other logic is needed (I took a look back at https://github.com/iterative/dvc/issues/4294 and https://github.com/iterative/dvc/pull/4262 but wasn't clear why this is all needed).",
    "repository_url": "https://api.github.com/repos/iterative/dvc",
    "repository_clone_url": "https://github.com/iterative/dvc",
    "repository_name": "dvc",
    "diff_url": "https://github.com/iterative/dvc/pull/10026.diff",
    "merged_at": "2023-10-16T20:28:29Z"
  }
]